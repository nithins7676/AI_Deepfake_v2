{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4737549,"sourceType":"datasetVersion","datasetId":2437902},{"sourceId":11473304,"sourceType":"datasetVersion","datasetId":7190440}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"prithivsakthiur/deepfake-vs-real-20k\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:24:37.917661Z","iopub.execute_input":"2025-11-23T15:24:37.917907Z","iopub.status.idle":"2025-11-23T15:24:38.586353Z","shell.execute_reply.started":"2025-11-23T15:24:37.917885Z","shell.execute_reply":"2025-11-23T15:24:38.585713Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/deepfake-vs-real-20k\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\nroot = \"/kaggle/input/deepfake-vs-real-20k/Deep-vs-Real\"\n\nfor dirpath, dirs, files in os.walk(root):\n    print(\"DIR:\", dirpath)\n    print(\"SUBFOLDERS:\", dirs)\n    print(\"FILES:\", len(files))\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:24:38.588193Z","iopub.execute_input":"2025-11-23T15:24:38.588403Z","iopub.status.idle":"2025-11-23T15:24:38.598015Z","shell.execute_reply.started":"2025-11-23T15:24:38.588386Z","shell.execute_reply":"2025-11-23T15:24:38.597329Z"}},"outputs":[{"name":"stdout","text":"DIR: /kaggle/input/deepfake-vs-real-20k/Deep-vs-Real\nSUBFOLDERS: ['Deepfake', 'Real']\nFILES: 0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n\ndeepfake_dir = \"/kaggle/input/deepfake-vs-real-20k/Deep-vs-Real/Deepfake\"\nreal_dir = \"/kaggle/input/deepfake-vs-real-20k/Deep-vs-Real/Real\"\n\nprint(\"Deepfake count:\", len(os.listdir(deepfake_dir)))\nprint(\"Real count:\", len(os.listdir(real_dir)))\n\n# Print first 10 filenames\nprint(\"Sample Deepfake files:\", os.listdir(deepfake_dir)[:10])\nprint(\"Sample Real files:\", os.listdir(real_dir)[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:24:38.598827Z","iopub.execute_input":"2025-11-23T15:24:38.598988Z","iopub.status.idle":"2025-11-23T15:24:38.825506Z","shell.execute_reply.started":"2025-11-23T15:24:38.598974Z","shell.execute_reply":"2025-11-23T15:24:38.824729Z"}},"outputs":[{"name":"stdout","text":"Deepfake count: 9576\nReal count: 9643\nSample Deepfake files: ['111 (1313).jpg', 'bad_1975.jpg', 'bad_463.jpg', '888 (120).jpg', '888 (1282).jpg', '888 (697).jpg', 'b (4173).jpg', '888 (508).jpg', '111 (316).jpg', '111 (1123).jpg']\nSample Real files: ['CCO (4029).png', 'CCO (2866).jpg', 'CCO (2047).jpg', 'CCO (3656).png', 'CCO (1107).jpg', 'CCO (235).png', 'CCO (2584).jpg', 'CCO (3663).jpg', 'CCO (4819).png', 'CCO (4583).png']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os, shutil\nfrom sklearn.model_selection import train_test_split\n\nroot = \"/kaggle/input/deepfake-vs-real-20k/Deep-vs-Real\"\nfake_dir = os.path.join(root, \"Deepfake\")\nreal_dir = os.path.join(root, \"Real\")\n\n# Output dirs\nout_root = \"/kaggle/working/data\"\ntrain_fake = os.path.join(out_root, \"train/fake\")\ntrain_real = os.path.join(out_root, \"train/real\")\nval_fake = os.path.join(out_root, \"val/fake\")\nval_real = os.path.join(out_root, \"val/real\")\n\nfor d in [train_fake, train_real, val_fake, val_real]:\n    os.makedirs(d, exist_ok=True)\n\nfake_files = [os.path.join(fake_dir, f) for f in os.listdir(fake_dir)]\nreal_files = [os.path.join(real_dir, f) for f in os.listdir(real_dir)]\n\nfake_train, fake_val = train_test_split(fake_files, test_size=0.2, random_state=42)\nreal_train, real_val = train_test_split(real_files, test_size=0.2, random_state=42)\n\ndef copy_files(file_list, dest):\n    for f in file_list:\n        shutil.copy(f, dest)\n\ncopy_files(fake_train, train_fake)\ncopy_files(fake_val, val_fake)\ncopy_files(real_train, train_real)\ncopy_files(real_val, val_real)\n\nprint(\"Done! Train/Val folders created in /kaggle/working/data\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:24:38.826545Z","iopub.execute_input":"2025-11-23T15:24:38.826818Z","iopub.status.idle":"2025-11-23T15:28:11.487599Z","shell.execute_reply.started":"2025-11-23T15:24:38.826794Z","shell.execute_reply":"2025-11-23T15:28:11.486706Z"}},"outputs":[{"name":"stdout","text":"Done! Train/Val folders created in /kaggle/working/data\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import kagglehub\n\npath = kagglehub.dataset_download(\"selfishgene/synthetic-faces-high-quality-sfhq-part-1\")\n\nprint(\"Path to dataset files:\", path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:28:11.488392Z","iopub.execute_input":"2025-11-23T15:28:11.488834Z","iopub.status.idle":"2025-11-23T15:28:11.676042Z","shell.execute_reply.started":"2025-11-23T15:28:11.488808Z","shell.execute_reply":"2025-11-23T15:28:11.675432Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/synthetic-faces-high-quality-sfhq-part-1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\n\nroot = \"/kaggle/input/synthetic-faces-high-quality-sfhq-part-1\"\n\nfor dirpath, dirs, files in os.walk(root):\n    print(\"DIR:\", dirpath)\n    print(\"SUBFOLDERS:\", dirs)\n    print(\"FILES:\", len(files))\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:28:11.676683Z","iopub.execute_input":"2025-11-23T15:28:11.676911Z","iopub.status.idle":"2025-11-23T15:28:11.684168Z","shell.execute_reply.started":"2025-11-23T15:28:11.676886Z","shell.execute_reply":"2025-11-23T15:28:11.683655Z"}},"outputs":[{"name":"stdout","text":"DIR: /kaggle/input/synthetic-faces-high-quality-sfhq-part-1\nSUBFOLDERS: ['pretrained_features', 'a small sample (550 images)', 'a tiny sample (30 images)', 'landmarks', 'images', 'segmentations']\nFILES: 0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\n\nroot = \"/kaggle/input/synthetic-faces-high-quality-sfhq-part-1\"\n\n# Correct folder: images/images\nimages_dir = os.path.join(root, \"images/images\")\nprint(\"Images folder:\", images_dir)\n\n# List only image files\nall_files = os.listdir(images_dir)\nimage_files = [f for f in all_files if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n\nprint(\"Number of images:\", len(image_files))\nprint(\"First 20 images:\", image_files[:20])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:28:11.686219Z","iopub.execute_input":"2025-11-23T15:28:11.686389Z","iopub.status.idle":"2025-11-23T15:28:12.624758Z","shell.execute_reply.started":"2025-11-23T15:28:11.686375Z","shell.execute_reply":"2025-11-23T15:28:12.624029Z"}},"outputs":[{"name":"stdout","text":"Images folder: /kaggle/input/synthetic-faces-high-quality-sfhq-part-1/images/images\nNumber of images: 89785\nFirst 20 images: ['SFHQ_pt1_00019489.jpg', 'SFHQ_pt1_00077727.jpg', 'SFHQ_pt1_00075412.jpg', 'SFHQ_pt1_00025430.jpg', 'SFHQ_pt1_00088498.jpg', 'SFHQ_pt1_00007969.jpg', 'SFHQ_pt1_00036628.jpg', 'SFHQ_pt1_00065041.jpg', 'SFHQ_pt1_00056790.jpg', 'SFHQ_pt1_00052931.jpg', 'SFHQ_pt1_00026787.jpg', 'SFHQ_pt1_00035403.jpg', 'SFHQ_pt1_00088383.jpg', 'SFHQ_pt1_00056709.jpg', 'SFHQ_pt1_00086966.jpg', 'SFHQ_pt1_00043607.jpg', 'SFHQ_pt1_00001582.jpg', 'SFHQ_pt1_00085462.jpg', 'SFHQ_pt1_00080096.jpg', 'SFHQ_pt1_00033693.jpg']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\n\nai_train = \"/kaggle/working/data/train/aifake\"\nai_val   = \"/kaggle/working/data/val/aifake\"\n\nos.makedirs(ai_train, exist_ok=True)\nos.makedirs(ai_val, exist_ok=True)\n\nprint(\"AI folders created!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:28:12.625431Z","iopub.execute_input":"2025-11-23T15:28:12.625676Z","iopub.status.idle":"2025-11-23T15:28:12.630356Z","shell.execute_reply.started":"2025-11-23T15:28:12.625658Z","shell.execute_reply":"2025-11-23T15:28:12.629792Z"}},"outputs":[{"name":"stdout","text":"AI folders created!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os, shutil\nfrom sklearn.model_selection import train_test_split\n\nsynth_root = \"/kaggle/input/synthetic-faces-high-quality-sfhq-part-1/images/images\"\nall_imgs = [os.path.join(synth_root, f) \n            for f in os.listdir(synth_root) \n            if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n\n# LIMIT to 2500 images\nall_imgs = all_imgs[:2500]\n\ntrain_ai, val_ai = train_test_split(all_imgs, test_size=0.2, random_state=42)\n\ndef copy_files(files, dest):\n    for f in files:\n        shutil.copy(f, dest)\n\ncopy_files(train_ai, ai_train)\ncopy_files(val_ai, ai_val)\n\nprint(\"Limited synthetic images added!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:28:12.631189Z","iopub.execute_input":"2025-11-23T15:28:12.631436Z","iopub.status.idle":"2025-11-23T15:28:33.925361Z","shell.execute_reply.started":"2025-11-23T15:28:12.631410Z","shell.execute_reply":"2025-11-23T15:28:33.924577Z"}},"outputs":[{"name":"stdout","text":"Limited synthetic images added!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\n\nbase = \"/kaggle/working/data\"\n\nfor split in [\"train\", \"val\"]:\n    print(f\"\\n=== {split.upper()} FOLDERS ===\")\n    folder = os.path.join(base, split)\n    print(os.listdir(folder))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:28:33.926270Z","iopub.execute_input":"2025-11-23T15:28:33.926651Z","iopub.status.idle":"2025-11-23T15:28:33.931259Z","shell.execute_reply.started":"2025-11-23T15:28:33.926624Z","shell.execute_reply":"2025-11-23T15:28:33.930522Z"}},"outputs":[{"name":"stdout","text":"\n=== TRAIN FOLDERS ===\n['real', 'fake', 'aifake']\n\n=== VAL FOLDERS ===\n['real', 'fake', 'aifake']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntrain_dir = \"/kaggle/working/data/train\"\nval_dir   = \"/kaggle/working/data/val\"\n\ntransform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n])\n\ntrain_ds = datasets.ImageFolder(train_dir, transform)\nval_ds   = datasets.ImageFolder(val_dir, transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n\nprint(\"Class mapping:\", train_ds.class_to_idx)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:59:45.785756Z","iopub.execute_input":"2025-11-23T15:59:45.786026Z","iopub.status.idle":"2025-11-23T15:59:45.837560Z","shell.execute_reply.started":"2025-11-23T15:59:45.786005Z","shell.execute_reply":"2025-11-23T15:59:45.836827Z"}},"outputs":[{"name":"stdout","text":"Class mapping: {'aifake': 0, 'fake': 1, 'real': 2}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model = models.vit_b_16(weights=\"IMAGENET1K_V1\")\nmodel.heads.head = nn.Linear(768, 3)  # 3 classes\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:00:25.796595Z","iopub.execute_input":"2025-11-23T16:00:25.797301Z","iopub.status.idle":"2025-11-23T16:00:26.925850Z","shell.execute_reply.started":"2025-11-23T16:00:25.797273Z","shell.execute_reply":"2025-11-23T16:00:26.925234Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"epochs = 5\n\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for imgs, labels in train_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {total_loss/len(train_loader):.4f}\")\n\n    # Validation\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for imgs, labels in val_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            _, predicted = torch.max(outputs, 1)\n\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    print(f\"Val Accuracy: {100 * correct/total:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:00:43.087677Z","iopub.execute_input":"2025-11-23T16:00:43.087954Z","iopub.status.idle":"2025-11-23T17:02:32.742426Z","shell.execute_reply.started":"2025-11-23T16:00:43.087934Z","shell.execute_reply":"2025-11-23T17:02:32.741245Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5 - Train Loss: 0.1078\nVal Accuracy: 98.41%\nEpoch 2/5 - Train Loss: 0.0299\nVal Accuracy: 98.00%\nEpoch 3/5 - Train Loss: 0.0207\nVal Accuracy: 99.17%\nEpoch 4/5 - Train Loss: 0.0133\nVal Accuracy: 99.13%\nEpoch 5/5 - Train Loss: 0.0128\nVal Accuracy: 99.15%\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/vit3class.pth\")\nprint(\"Model saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:02:55.763673Z","iopub.execute_input":"2025-11-23T17:02:55.763969Z","iopub.status.idle":"2025-11-23T17:02:56.206046Z","shell.execute_reply.started":"2025-11-23T17:02:55.763943Z","shell.execute_reply":"2025-11-23T17:02:56.205365Z"}},"outputs":[{"name":"stdout","text":"Model saved!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom PIL import Image\nimport torch.nn.functional as F\n\n# Paths\nmodel_path = \"/kaggle/working/vit3class.pth\"   # change to your actual filename\nimage_path = \"/kaggle/working/data/val/fake/111 (1024).jpg\"  # test image\n\n# Load model\ndevice = \"cuda\"\nmodel.eval()\n\nstate = torch.load(model_path, map_location=device)\nmodel.load_state_dict(state)\nmodel.to(device)\n\n# Transform\ntransform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n])\n\nimg = Image.open(image_path).convert(\"RGB\")\nimg_t = transform(img).unsqueeze(0).to(device)\n\nwith torch.no_grad():\n    logits = model(img_t)\n    probs = F.softmax(logits, dim=1)\n\nprint(\"Class probabilities:\", probs.cpu().numpy())\nprint(\"Predicted class:\", probs.argmax().item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:08:14.808287Z","iopub.execute_input":"2025-11-23T17:08:14.808623Z","iopub.status.idle":"2025-11-23T17:08:15.106859Z","shell.execute_reply.started":"2025-11-23T17:08:14.808598Z","shell.execute_reply":"2025-11-23T17:08:15.106066Z"}},"outputs":[{"name":"stdout","text":"Class probabilities: [[3.0754916e-05 9.9995410e-01 1.5165953e-05]]\nPredicted class: 1\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!zip -r vit_model.zip /kaggle/working/vit3class.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:22:08.832177Z","iopub.execute_input":"2025-11-23T17:22:08.833000Z","iopub.status.idle":"2025-11-23T17:22:26.505178Z","shell.execute_reply.started":"2025-11-23T17:22:08.832965Z","shell.execute_reply":"2025-11-23T17:22:26.504465Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/vit3class.pth (deflated 7%)\n","output_type":"stream"}],"execution_count":29}]}